{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01703ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import importlib\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2925cca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset' from '/home/pakumar/teams/ece251c-team-11/dataset.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c64da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU devices: 1\n",
      "GPU device name: GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# define device type - cuda:0 or cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "kwargs = {'num_workers': 4, 'pin_memory': False} if device.type == \"cuda\" else {}\n",
    "\n",
    "# Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(\"Number of GPU devices:\", torch.cuda.device_count())\n",
    "    print(\"GPU device name:\", torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 3), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3, 3), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d03383e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "TEST_BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb26ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 2),\n",
    "            stride=(2, 1),\n",
    "            padding=(0, 1)\n",
    "        )\n",
    "        \n",
    "        self.norm = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        2D Causal convolution.\n",
    "        Args:\n",
    "            x: [batch_size, num_channels, F, T]\n",
    "        Returns:\n",
    "            [B, C, F, T]\n",
    "        \"\"\"\n",
    "        x = self.conv_layer(x)\n",
    "        x = x[:, :, :, :-1]  # chomp size\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ca455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalTransConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, is_last=False, output_padding=(0, 0)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.ConvTranspose2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(3, 2),\n",
    "            stride=(2, 1),\n",
    "            output_padding=output_padding\n",
    "        \n",
    "        )\n",
    "        self.norm = nn.BatchNorm2d(num_features=out_channels)\n",
    "        if is_last:\n",
    "            self.activation = nn.ReLU()\n",
    "        else:\n",
    "            self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        2D Causal convolution.\n",
    "        Args:\n",
    "            x: [B, C, F, T]\n",
    "        Returns:\n",
    "            [B, C, F, T]\n",
    "        \"\"\"\n",
    "        x = self.conv(x)\n",
    "        x = x[:, :, :, :-1]  # chomp size\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163c8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRecNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: [batch size, channels=1, T, n_fft]\n",
    "    Output: [batch size, T, n_fft]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvRecNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.conv_block_1 = CausalConvBlock(1, 16)\n",
    "        self.conv_block_2 = CausalConvBlock(16, 32)\n",
    "        self.conv_block_3 = CausalConvBlock(32, 64)\n",
    "        self.conv_block_4 = CausalConvBlock(64, 128)\n",
    "        self.conv_block_5 = CausalConvBlock(128, 256)\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm_layer = nn.LSTM(input_size=1024, hidden_size=1024, num_layers=2, batch_first=True)\n",
    "        \n",
    "        self.tran_conv_block_1 = CausalTransConvBlock(256 + 256, 128)\n",
    "        self.tran_conv_block_2 = CausalTransConvBlock(128 + 128, 64)\n",
    "        self.tran_conv_block_3 = CausalTransConvBlock(64 + 64, 32)\n",
    "        self.tran_conv_block_4 = CausalTransConvBlock(32 + 32, 16, output_padding=(1, 0))\n",
    "        self.tran_conv_block_5 = CausalTransConvBlock(16 + 16, 1, is_last=True)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.lstm_layer.flatten_parameters()\n",
    "\n",
    "        e_1 = self.conv_block_1(x)\n",
    "        e_2 = self.conv_block_2(e_1)\n",
    "        e_3 = self.conv_block_3(e_2)\n",
    "        e_4 = self.conv_block_4(e_3)\n",
    "        e_5 = self.conv_block_5(e_4)  # [2, 256, 4, 200]\n",
    "\n",
    "        batch_size, n_channels, n_f_bins, n_frame_size = e_5.shape\n",
    "\n",
    "        # [2, 256, 4, 200] = [2, 1024, 200] => [2, 200, 1024]\n",
    "        lstm_in = e_5.reshape(batch_size, n_channels * n_f_bins, n_frame_size).permute(0, 2, 1)\n",
    "        lstm_out, _ = self.lstm_layer(lstm_in)  # [2, 200, 1024]\n",
    "        lstm_out = lstm_out.permute(0, 2, 1).reshape(batch_size, n_channels, n_f_bins, n_frame_size)  # [2, 256, 4, 200]\n",
    "\n",
    "        d_1 = self.tran_conv_block_1(torch.cat((lstm_out, e_5), 1))\n",
    "        d_2 = self.tran_conv_block_2(torch.cat((d_1, e_4), 1))\n",
    "        d_3 = self.tran_conv_block_3(torch.cat((d_2, e_3), 1))\n",
    "        d_4 = self.tran_conv_block_4(torch.cat((d_3, e_2), 1))\n",
    "        d_5 = self.tran_conv_block_5(torch.cat((d_4, e_1), 1))\n",
    "\n",
    "        return d_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aabd1457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 161, 200])\n"
     ]
    }
   ],
   "source": [
    "model = ConvRecNet()\n",
    "a = torch.rand(2, 1, 161, 200)\n",
    "print(model(a).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abdca291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = dataset.SpeechDataset('train')\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, collate_fn=dataset.custom_collate_fn)\n",
    "# print(\"Train dataset size:\", len(train_dataloader))\n",
    "\n",
    "# itr = next(iter(train_dataloader))\n",
    "\n",
    "# # Print shape of spectrogram across a batch\n",
    "# for k in range(len(itr[0])):\n",
    "#     print(itr[0][k].shape, itr[1][k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a58cd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 4259\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset.SpeechDataset('test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, collate_fn=dataset.custom_collate_fn)\n",
    "print(\"Test dataset size:\", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d121bb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 3105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821b85f657284bcf954bf74cf330f928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LEN_ = []\n",
    "MIN_LEN_ = []\n",
    "for split in ['train', 'test', 'val']:\n",
    "    dataset_ = dataset.SpeechDataset(split)\n",
    "    dataloader_ = DataLoader(dataset_, batch_size=16, collate_fn=dataset.custom_collate_fn)\n",
    "    print(\"%s dataset size: %d\" %(split, len(dataloader_)))\n",
    "\n",
    "    max_ = 0\n",
    "    min_ = float(\"inf\")\n",
    "    for itr, (x_batch, y_batch) in tqdm(enumerate(dataloader_)):\n",
    "        for k in range(len(x_batch)):\n",
    "            max_ = max(max_, x_batch[k].size()[1])\n",
    "            min_ = min(min_, x_batch[k].size()[1])\n",
    "    MAX_LEN_.append(max_)\n",
    "    MIN_LEN_.append(min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9b136fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1308/3642233573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (4, 4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# understand dataloader\n",
    "for i in range(3):\n",
    "    clean_spec, noisy_spec = next(iter(test_dataloader))\n",
    "    print(len(clean_spec), len(noisy_spec))  # (4, 4)\n",
    "\n",
    "    \n",
    "    print(clean_spec[0].shape, clean_spec[1].shape, clean_spec[2].shape, clean_spec[3].shape)\n",
    "    print(noisy_spec[0].shape, noisy_spec[1].shape, noisy_spec[2].shape, noisy_spec[3].shape)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1272dd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d934c2c68ad4139bd14c0aa0b584067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1025, 127]) torch.Size([1025, 122]) torch.Size([1025, 20]) torch.Size([1025, 408])\n",
      "1\n",
      "torch.Size([1025, 149]) torch.Size([1025, 292]) torch.Size([1025, 186]) torch.Size([1025, 419])\n",
      "2\n",
      "torch.Size([1025, 289]) torch.Size([1025, 175]) torch.Size([1025, 111]) torch.Size([1025, 22])\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    for itr, (x_batch, y_batch) in enumerate(test_dataloader):\n",
    "        print(itr)\n",
    "        \n",
    "#         x_batch = torch.tensor(x_batch)\n",
    "\n",
    "#         print(x_batch.shape, y_batch.shape)\n",
    "        print(x_batch[0].shape, x_batch[1].shape, x_batch[2].shape, x_batch[3].shape)\n",
    "\n",
    "        if itr > 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d81c2b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n",
      "torch.Size([1025, 111])\n"
     ]
    }
   ],
   "source": [
    "print(len(itr[0]), len(itr[1]))\n",
    "print(itr[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee378f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
