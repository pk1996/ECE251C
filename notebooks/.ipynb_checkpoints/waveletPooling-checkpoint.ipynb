{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d56bb221",
   "metadata": {},
   "source": [
    "## PTWT\n",
    "\n",
    "1. Use ptwt to calculate 2nd order wavelet decomposition\n",
    "2. Reconstruct using all the information\n",
    "3. Reconstruct using only the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab2e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ptwt, pywt, torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from matplotlib import pyplot as plt\n",
    "face = np.transpose(scipy.misc.face(),\n",
    "                    [2, 0, 1]).astype(np.float64)\n",
    "pytorch_face = torch.tensor(face)\n",
    "coefficients = ptwt.wavedec2(pytorch_face, pywt.Wavelet(\"haar\"),\n",
    "                             level=2, mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47adff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_(x):\n",
    "    print(x.shape)\n",
    "    plt.imshow(x.numpy().squeeze().transpose(1,2,0)/255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using both first and second order subbands - size remains same\n",
    "reconstruction = ptwt.waverec2(coefficients, pywt.Wavelet(\"haar\"))\n",
    "plot_(reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructing using second level subbands. Leads to downsampling by a factor of 2\n",
    "c = []\n",
    "c.append(coefficients[0])\n",
    "c.append(coefficients[1])\n",
    "reconstruction_ = ptwt.waverec2(c, pywt.Wavelet(\"haar\"))\n",
    "plot_(reconstruction_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructing using strategy in paper - upsampled by a factor of 2\n",
    "# DWT(I) = (LL, (LH, HL, HH))\n",
    "# I (u2) = (LL, (LH, HL, HH), (LH(u2), HL(u2), HH(u2)))\n",
    "\n",
    "coefficients = ptwt.wavedec2(pytorch_face, pywt.Wavelet(\"haar\"),\n",
    "                             level=1, mode=\"constant\")\n",
    "c = coefficients\n",
    "upsample_ = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "c_2 = []\n",
    "for coef in coefficients[1]:\n",
    "    c_2.append(upsample_(coef))\n",
    "c.append((c_2))\n",
    "\n",
    "reconstruction_ = ptwt.waverec2(c, pywt.Wavelet(\"haar\"))\n",
    "plot_(reconstruction_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b65887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5baffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8534bb93",
   "metadata": {},
   "source": [
    "# Wavelet Pooling \n",
    "##### Implementing wavelet pooling as a subclass of torch.nn module and implementing the backpropagation via the backward hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da3148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ptwt, pywt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf25891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletPooling(nn.Module):\n",
    "    def __init__(self, wavelet):\n",
    "        super(WaveletPooling,self).__init__()\n",
    "        self.upsample_ = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.wavelet = wavelet\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        bs = x.size()[0]\n",
    "        FORWARD_OUTPUT_ = []\n",
    "        \n",
    "        # loop over input as batching not supported\n",
    "        for k in range(bs):\n",
    "            # coeffiecients - cx1xhxw\n",
    "            coefficients = ptwt.wavedec2(x[k,:,:,:], pywt.Wavelet(self.wavelet),\n",
    "                                        level=2, mode=\"constant\")\n",
    "            # 2nd order DWT\n",
    "            forward_output_ = ptwt.waverec2([coefficients[0], coefficients[1]], pywt.Wavelet(self.wavelet))\n",
    "            \n",
    "            # permute dim - 1xcxhxw\n",
    "            FORWARD_OUTPUT_.append(torch.permute(forward_output_, [1,0,2,3]))\n",
    "        \n",
    "        FORWARD_OUTPUT_ = torch.cat(FORWARD_OUTPUT_, dim = 0)\n",
    "        return FORWARD_OUTPUT_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336dd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_pooling_hook(module, inp, out):\n",
    "    '''\n",
    "    inp - gradient output from the layer\n",
    "    out - gradient inp to layer \n",
    "    '''\n",
    "\n",
    "#     print('gradient out at pooling layer ...')\n",
    "#     print(out[0].shape)\n",
    "#     grad_output = out[0].squeeze().permute(1,2,0).detach().numpy()\n",
    "#     plt.imshow(grad_output/255)\n",
    "#     plt.show()\n",
    "    \n",
    "    # Computing gradient using paper.\n",
    "    bs = out[0].size()[0]\n",
    "    BACKWARD_OUTPUT_ = []\n",
    "\n",
    "    # loop over input as batching not supported\n",
    "    for k in range(bs):\n",
    "        ## 1. 1st order DWT\n",
    "        coefficients = ptwt.wavedec2(torch.squeeze(out[0][k]), pywt.Wavelet(\"haar\"),\n",
    "                                        level=1, mode=\"constant\")\n",
    "        ## 2. upsample subbands\n",
    "        # LL\n",
    "        upsampled_subbands_ = coefficients\n",
    "        \n",
    "        # LH, HL, HH\n",
    "        upsampled_subbands_.append([])\n",
    "        for k in range(len(coefficients[1])):\n",
    "            upsampled_subbands_[-1].append(module.upsample_(coefficients[1][k]))\n",
    "        upsampled_subbands_[-1] = tuple(upsampled_subbands_[-1])  \n",
    "\n",
    "        ## 3. IDWT\n",
    "        backward_output_ = ptwt.waverec2(upsampled_subbands_, pywt.Wavelet(\"haar\"))\n",
    "        BACKWARD_OUTPUT_.append(backward_output_.permute(1,0,2,3))\n",
    "    \n",
    "    BACKWARD_OUTPUT_ = torch.cat(BACKWARD_OUTPUT_, dim = 0)\n",
    "    BACKWARD_OUTPUT_SHAPE_ = BACKWARD_OUTPUT_.shape\n",
    "    INPUT_SIZE_CAHCED_ = inp[0].size()\n",
    "        \n",
    "#     print('gradient in at pooling layer ...')\n",
    "#     print(BACKWARD_OUTPUT_.shape)\n",
    "#     grad_output = BACKWARD_OUTPUT_.squeeze().permute(1,2,0).detach().numpy()\n",
    "#     plt.imshow(grad_output/255)\n",
    "#     plt.show()\n",
    "    \n",
    "    return [BACKWARD_OUTPUT_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a800b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(c,3,1,1)\n",
    "        self.pool = WaveletPooling('haar')\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.pool(self.conv1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329277e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_fn(m,i,o):\n",
    "    print('gradient out at CNN layer ...')\n",
    "    print(o[0].shape)\n",
    "    grad_output = o[0].squeeze().permute(1,2,0).detach().numpy()\n",
    "    plt.imshow(grad_output/255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0517670",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3\n",
    "b = 1\n",
    "input_ = torch.tensor(np.transpose(scipy.misc.face(), [2, 0, 1]).astype(np.float64))[None,:,:,:] #torch.ones(b,c,4,4)\n",
    "input_.requires_grad = True\n",
    "b,c,h,w = input_.size()\n",
    "\n",
    "m = Model(c)\n",
    "m.pool.register_full_backward_hook(wavelet_pooling_hook)\n",
    "m.conv1.register_full_backward_hook(hook_fn)\n",
    "output_ = m(input_.float())\n",
    "\n",
    "(torch.mul(output_, output_).sum()/2).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65056c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = input_.squeeze().permute(1,2,0).detach().numpy()\n",
    "print(img_input.shape)\n",
    "plt.imshow(img_input/255)\n",
    "plt.show()\n",
    "\n",
    "img_output = output_.squeeze().permute(1,2,0).detach().numpy()\n",
    "print(img_output.shape)\n",
    "plt.imshow(img_output/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0cefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e8b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50659214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1effe606",
   "metadata": {},
   "source": [
    "## Analysing the output shape from pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec19e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3f8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "230ce766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletPooling(nn.Module):\n",
    "    def __init__(self, wavelet):\n",
    "        super(WaveletPooling,self).__init__()\n",
    "        self.upsample_ = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.wavelet = wavelet\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        bs = x.size()[0]\n",
    "        FORWARD_OUTPUT_ = []\n",
    "        \n",
    "        # loop over input as batching not supported\n",
    "        for k in range(bs):\n",
    "            # coeffiecients - cx1xhxw\n",
    "            coefficients = ptwt.wavedec2(x[k,:,:-1,:-1], pywt.Wavelet(self.wavelet),\n",
    "                                        level=2, mode=\"constant\")\n",
    "            # 2nd order DWT\n",
    "            forward_output_ = ptwt.waverec2([coefficients[0], coefficients[1]], pywt.Wavelet(self.wavelet))\n",
    "            \n",
    "            # permute dim - 1xcxhxw\n",
    "            FORWARD_OUTPUT_.append(torch.permute(forward_output_, [1,0,2,3]))\n",
    "        \n",
    "        FORWARD_OUTPUT_ = torch.cat(FORWARD_OUTPUT_, dim = 0)\n",
    "        return FORWARD_OUTPUT_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9361f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_pooling_hook(module, inp, out):\n",
    "    '''\n",
    "    inp - gradient output from the layer\n",
    "    out - gradient inp to layer \n",
    "    '''\n",
    "\n",
    "#     print('gradient out at pooling layer ...')\n",
    "#     print(out[0].shape)\n",
    "#     grad_output = out[0].squeeze().permute(1,2,0).detach().numpy()\n",
    "#     plt.imshow(grad_output/255)\n",
    "#     plt.show()\n",
    "    \n",
    "    # Computing gradient using paper.\n",
    "    bs = out[0].size()[0]\n",
    "    BACKWARD_OUTPUT_ = []\n",
    "\n",
    "    # loop over input as batching not supported\n",
    "    for k in range(bs):\n",
    "        ## 1. 1st order DWT\n",
    "        coefficients = ptwt.wavedec2(torch.squeeze(out[0][k]), pywt.Wavelet(\"haar\"),\n",
    "                                        level=1)#, mode=\"constant\")\n",
    "        ## 2. upsample subbands\n",
    "        # LL\n",
    "        upsampled_subbands_ = coefficients\n",
    "        \n",
    "        # LH, HL, HH\n",
    "        upsampled_subbands_.append([])\n",
    "        for k in range(len(coefficients[1])):\n",
    "            upsampled_subbands_[-1].append(module.upsample_(coefficients[1][k]))\n",
    "        upsampled_subbands_[-1] = tuple(upsampled_subbands_[-1])  \n",
    "\n",
    "        ## 3. IDWT\n",
    "        backward_output_ = ptwt.waverec2(upsampled_subbands_, pywt.Wavelet(\"haar\"))\n",
    "        BACKWARD_OUTPUT_.append(backward_output_.permute(1,0,2,3))\n",
    "    \n",
    "    BACKWARD_OUTPUT_ = torch.cat(BACKWARD_OUTPUT_, dim = 0)\n",
    "    \n",
    "    cw = 4-inp[0].shape[2]%4\n",
    "    ch = 4-inp[0].shape[3]%4\n",
    "    \n",
    "    if cw != 4:\n",
    "        BACKWARD_OUTPUT_ = BACKWARD_OUTPUT_[:,:,:-cw,:]\n",
    "    \n",
    "    if ch != 4:\n",
    "        BACKWARD_OUTPUT_ = BACKWARD_OUTPUT_[:,:,:,:-ch]\n",
    "        \n",
    "#     BACKWARD_OUTPUT_SHAPE_ = BACKWARD_OUTPUT_.shape\n",
    "#     INPUT_SIZE_CAHCED_ = inp[0].size()\n",
    "#     print('gradient in at pooling layer ...')\n",
    "#     print(BACKWARD_OUTPUT_.shape)\n",
    "#     grad_output = BACKWARD_OUTPUT_.squeeze().permute(1,2,0).detach().numpy()\n",
    "#     plt.imshow(grad_output/255)\n",
    "#     plt.show()\n",
    "    BACKWARD_OUTPUT_SHAPE_ = BACKWARD_OUTPUT_.shape\n",
    "    print(inp[0].shape, out[0].shape, cw, ch, BACKWARD_OUTPUT_SHAPE_)\n",
    "    \n",
    "    return [BACKWARD_OUTPUT_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "260e4d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPooling(nn.Module):\n",
    "    def __init__(self, N = 1, pooling = 'waveler'):\n",
    "        super(ModelPooling, self).__init__()\n",
    "        if pooling == 'wavelet':\n",
    "            self.pool = WaveletPooling('haar')\n",
    "        else:\n",
    "            self.pool = nn.MaxPool2d(3,2)\n",
    "        self.N = N\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        for i in range(self.N):\n",
    "            x = self.pool(x)\n",
    "            print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d9cce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass ....\n",
      "torch.Size([1, 3, 288, 64])\n",
      "torch.Size([1, 3, 144, 32])\n",
      "torch.Size([1, 3, 72, 16])\n",
      "torch.Size([1, 3, 36, 8])\n",
      "torch.Size([1, 3, 18, 4])\n",
      "torch.Size([1, 3, 10, 2])\n",
      "\n",
      "Backward pass ....\n"
     ]
    }
   ],
   "source": [
    "c = 3\n",
    "b = 1\n",
    "w = 288\n",
    "h = 64\n",
    "# input_ = torch.tensor(np.transpose(scipy.misc.face(), [2, 0, 1]).astype(np.float64))[None,:,:,:] #torch.ones(b,c,4,4)\n",
    "input_ = torch.randn(b,c,w,h)\n",
    "input_.requires_grad = True\n",
    "b,c,h,w = input_.size()\n",
    "\n",
    "\n",
    "print('Forward pass ....')\n",
    "# pooling = \"maxpool\"\n",
    "pooling = \"wavelet\"\n",
    "m = ModelPooling(N = 5, pooling=pooling)\n",
    "# if pooling == \"wavelet\":\n",
    "#     m.pool.register_full_backward_hook(wavelet_pooling_hook)\n",
    "output_ = m(input_.float())\n",
    "\n",
    "\n",
    "print('\\nBackward pass ....')\n",
    "(torch.mul(output_, output_).sum()/2).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b87e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76c206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
