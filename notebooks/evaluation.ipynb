{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e7ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice, randint\n",
    "from pathlib import Path\n",
    "\n",
    "import importlib\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "\n",
    "import ptwt, pywt\n",
    "\n",
    "from sphfile import SPHFile\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "\n",
    "import dataset\n",
    "from dataset import pickle_stft_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e115a3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset' from '/home/pakumar/teams/ece251c-team-11/code/dataset.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a396c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 1\n",
    "TEST_BATCH_SIZE = 1\n",
    "\n",
    "BASE_DIR = Path(os.getcwd()).parents[0]\n",
    "DATA_DIR = BASE_DIR / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5961b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl_data(split, num_samples):\n",
    "    pkl_file = DATA_DIR / 'pkl_files' / '{}_data'.format(split) / 'clean_mixed_data_{}.pickle'.format(num_samples)\n",
    "    if not pkl_file.is_file():\n",
    "        print('Generating data ...')\n",
    "        signal_len_lst = pickle_stft_data(split, num_samples=num_samples)\n",
    "        plot_signal_stats(signal_len_lst)\n",
    "        \n",
    "    with open(pkl_file, 'rb') as handle:\n",
    "        clean_mixed_data_dict = pickle.load(handle)\n",
    "    \n",
    "    return clean_mixed_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d134c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, split='train', num_samples=1000, alpha=0.8):\n",
    "        assert split in ['train', 'val', 'test'], \"Invalid split\"\n",
    "        self.split = split\n",
    "        self.alpha = alpha\n",
    "        self.num_samples = num_samples\n",
    "        self.clean_mixed_data_dict = load_pkl_data(split, num_samples)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "#         return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        stft_clean = self.clean_mixed_data_dict['clean'][idx]\n",
    "        stft_mixed = self.clean_mixed_data_dict['mixed'][idx]\n",
    "        \n",
    "        return stft_clean, stft_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4edbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 500\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SpeechDataset('test', num_samples=500)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, collate_fn=dataset.custom_collate_fn)\n",
    "print(\"Test dataset size:\", len(test_dataloader))\n",
    "# dataset_stats(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0376bae7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10303/3819088304.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# model = models.get_architecture(model_checkpoint[\"arch\"], args.dataset_name, device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_save_path = os.path.join(BASE_DIR, \"trained_model_ckpts/checkpoint.pth.tar\")\n",
    "model_checkpoint = torch.load(f=model_save_path)\n",
    "# model = models.get_architecture(model_checkpoint[\"arch\"], args.dataset_name, device)\n",
    "model.load_state_dict(model_checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c9787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
